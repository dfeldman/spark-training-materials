{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Spark\n",
    "\n",
    "### This is based on a public lesson from Databricks [available here](https://github.com/databricks/spark-training/tree/master/machine-learning)\n",
    "\n",
    "Have you ever wondered how Netflix knows what movies you will like, based just on your ratings of other movies? This is a machine learning problem called Collaborative Filtering. Spark comes with a pretty good algorithm for solving the collaborative filtering problem called Alternating Least Squares. We'll build a model of a real movie ratings data set, and then see what your predictions are for various movies!\n",
    "\n",
    "Here are some more details:\n",
    " - The Movielens data set comes from the University of Minnesota CS department -- it was one of the first consumer recommender systems in the early 2000s. It is still online [here](http://movielens.org).\n",
    " - We won't be doing any serious cross-validation of the model, although Spark does make that relatively easy'\n",
    " - The SparkML guide is [here](http://spark.apache.org/docs/latest/ml-guide.html). The Spark Collaborative Filtering guide (very relevant) is [here](http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html)\n",
    " - An article on the ALS learning algorithm is [here](http://bugra.github.io/work/notes/2014-04-19/alternating-least-squares-method-for-collaborative-filtering/). The original research paper is [here](http://dl.acm.org/citation.cfm?id=1608614)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql\n",
    "import pandas, pandas.tools.plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "try: sc = pyspark.SparkContext('local[*]')\n",
    "except ValueError: pass\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "\n",
    "# Useful function for displaying a DataFrame in a nice-looking way\n",
    "def show(df):\n",
    "   display(HTML(\n",
    "    '<table><tr><th>{}</th></tr><tr>{}</tr></table>'.format(\n",
    "        '</th><th>'.join(str(_) for _ in df.columns),\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in df.take(50))\n",
    "        )\n",
    "     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions for loading and parsing the Movielens data set\n",
    "\n",
    "# To save time training, limit the number of ratings used\n",
    "LIMIT=100000\n",
    "\n",
    "# /data/movie-ratings.dat is in this format: \n",
    "# userid::movieId::rating (1-5 scale)::timestamp (we ignore this)\n",
    "# 1::1193::5::978300760\n",
    "# 1::661::3::978302109\n",
    "# 1::914::3::978301968\n",
    "# 1::3408::4::978300275\n",
    "# 1::2355::5::978824291\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "def parseRating(line):\n",
    "    # Parse a user-movie-rating triple from /data/movie-ratings.dat\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return (int(fields[0]), int(fields[1]), float(fields[2]))\n",
    "    \n",
    "def parseMovie(line):\n",
    "    # Parse a movie ID and title from /data/movies.dat\n",
    "    fields = line.strip().split(\"::\")          \n",
    "    return int(fields[0]), fields[1] \n",
    "    \n",
    "def loadRatings():\n",
    "    # load and parse the entire movie-ratings file\n",
    "    f = open('../data/movie-ratings.dat', 'r').readlines()\n",
    "    ratings = [parseRating(l) for l in f]\n",
    "    # Skip any ratings of 0 (these are bad data)\n",
    "    ratings = [Rating(l[0], l[1], l[2]) for l in ratings if l[2] > 0][:LIMIT]\n",
    "    return ratings\n",
    "\n",
    "# Preload all the movie names into a global dict for easy lookup\n",
    "\n",
    "movieNamesDict = {}\n",
    "for movie in open('../data/movies.dat', encoding = \"ISO-8859-1\").readlines():\n",
    "    parsed = parseMovie(movie)\n",
    "    movieNamesDict[parsed[0]] = parsed[1]\n",
    "\n",
    "def getNameOfMovie(movie):\n",
    "    if movie in movieNamesDict: return movieNamesDict[movie]\n",
    "    else: return 'Unknown'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 20\n",
    "numIterations = 15\n",
    "ratingsRdd = sc.parallelize(loadRatings())\n",
    "model = ALS.train(ratingsRdd, rank, numIterations, 0.01)\n",
    "\n",
    "# Compute the Mean Squared Error so we know how good our model is\n",
    "testdata = ratingsRdd.map(lambda p: (p[0], p[1]))\n",
    "# Try to reconstruct all the ratings from the model\n",
    "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "# Join them with the real ratings\n",
    "ratesAndPreds = ratingsRdd.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "# Compute the MSE between the real rating and the predicted rating\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's rate some movies (as if we were choosing star ratings using the Netflix interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myRatings = [\n",
    "(1, 1),     # Toy Story\n",
    "(780, 1000),   # Independence Day\n",
    "(590, 1),   # Dances with Wolves\n",
    "(648, 1000),   # Mission: Impossible\n",
    "(344, 1),   # Ace Ventura: Pet Detective\n",
    "(165, 1000),   # Die Hard With a Vengeance\n",
    "(153, 1),   # Batman Forever\n",
    "(597, 1),   # Pretty Woman\n",
    "(1580, 1),  # Men in Black\n",
    "(231, 1)   # Dumb and Dumber\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add our ratings under user ID 0, and re-train the model. Then find the top-scoring movies from the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Each of our ratings will have user ID 0\n",
    "myRatingsRdd = sc.parallelize([Rating(0, p[0], p[1]) for p in myRatings])\n",
    "\n",
    "# Train the model with both the original ratings, and the new ratings for \"user 0\"\n",
    "model = ALS.train(ratingsRdd.union(myRatingsRdd), rank, numIterations)\n",
    "\n",
    "# The \"candidates rows\" will have user ID 0, real movie IDs, and no rating\n",
    "candidates = ratingsRdd.map(lambda rating: [0, rating[1]])\n",
    "\n",
    "# We ask the algorithm to fill in a rating for each candidate\n",
    "predictions = model.predictAll(candidates)\n",
    "\n",
    "# Sort them so the highest predictions are at the top\n",
    "topPredictions = predictions.distinct().map(lambda r: (r[2], r[1])).sortByKey(ascending=False)\n",
    "\n",
    "# Get the name of each movie in topPredictions\n",
    "topPredictionsWithNames = topPredictions.map(lambda x: (x[0], x[1], getNameOfMovie(x[1])))\n",
    "\n",
    "topPredictionsDF = topPredictionsWithNames.toDF([\"Predicted Rating\",\"Movie ID\",\"Movie Title\"])\n",
    "show(topPredictionsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "1. One problem with this program is that the movies that you initially rated always show up in the output as well. Can you remove them?\n",
    "2. The Iterations and Rank parameters have a big effect on the quality of the model. Can you add a loop to optimize these?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
